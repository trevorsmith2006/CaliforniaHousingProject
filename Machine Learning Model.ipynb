{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a Machine Learning Model\n",
    "\n",
    "In the other notebooks we've done some exploratory analysis, then developed a data cleaning pipeline to prepare the data for a ML model. Here we will import our training and testing data sets, run them through the pipeline and begin exploring what kind of ML model we can use to predict the median home prices of US Census Bureau districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data tools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copy and pasted our pipeline code from PreprocessingPipeline.ipynb\n",
    "\"\"\"\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[\"total_rooms\"]/X[\"households\"]\n",
    "        bedrooms_per_room = X[\"total_bedrooms\"]/X[\"total_rooms\"]\n",
    "        population_per_household = X[\"population\"]/X[\"households\"]\n",
    "        \n",
    "        return np.c_[X, rooms_per_household, bedrooms_per_room, population_per_household]\n",
    "\n",
    "# create a pipeline for our numerical attributes only\n",
    "num_pipeline = Pipeline([\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# combine the numerical pipeline with the categorical one (just one-hot encoding)\n",
    "num_attribs = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', \n",
    "               'population', 'households', 'median_income']\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our data, which we've already split into training and test sets\n",
    "housing_train = pd.read_pickle(\"StratifiedTrainingSet.pkl\")\n",
    "housing_test = pd.read_pickle(\"StratifiedTestSet.pkl\")\n",
    "\n",
    "# seperate labels from features, run data cleaning on the features\n",
    "# our variable naming conventions: X for features, y for labels\n",
    "X_train = full_pipeline.fit_transform(housing_train.drop(columns=[\"median_house_value\"],axis=1))\n",
    "y_train = housing_train[\"median_house_value\"]\n",
    "\n",
    "# IMPORTANT: don't touch the test sets until we have a model we are confident in\n",
    "X_test = full_pipeline.fit_transform(housing_test.drop(columns=[\"median_house_value\"],axis=1))\n",
    "y_test = housing_test[\"median_house_value\"]\n",
    "\n",
    "# reintroduce column labels by changing X back into a DataFrame\n",
    "X_cols = ['longitude','latitude','housing_median_age','total_rooms',\n",
    "          'total_bedrooms','population','households','median_income',\n",
    "          'rooms_per_household', 'bedrooms_per_room', 'population_per_household', \n",
    "          '<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X_cols)\n",
    "X_test = pd.DataFrame(X_test, columns=X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16512 entries, 0 to 16511\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   longitude                 16512 non-null  float64\n",
      " 1   latitude                  16512 non-null  float64\n",
      " 2   housing_median_age        16512 non-null  float64\n",
      " 3   total_rooms               16512 non-null  float64\n",
      " 4   total_bedrooms            16512 non-null  float64\n",
      " 5   population                16512 non-null  float64\n",
      " 6   households                16512 non-null  float64\n",
      " 7   median_income             16512 non-null  float64\n",
      " 8   rooms_per_household       16512 non-null  float64\n",
      " 9   bedrooms_per_room         16512 non-null  float64\n",
      " 10  population_per_household  16512 non-null  float64\n",
      " 11  <1H OCEAN                 16512 non-null  float64\n",
      " 12  INLAND                    16512 non-null  float64\n",
      " 13  ISLAND                    16512 non-null  float64\n",
      " 14  NEAR BAY                  16512 non-null  float64\n",
      " 15  NEAR OCEAN                16512 non-null  float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['longitude', 'latitude', 'total_rooms', 'total_bedrooms', 'population', 'households']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16512 entries, 0 to 16511\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   housing_median_age        16512 non-null  float64\n",
      " 1   median_income             16512 non-null  float64\n",
      " 2   rooms_per_household       16512 non-null  float64\n",
      " 3   bedrooms_per_room         16512 non-null  float64\n",
      " 4   population_per_household  16512 non-null  float64\n",
      " 5   <1H OCEAN                 16512 non-null  float64\n",
      " 6   INLAND                    16512 non-null  float64\n",
      " 7   ISLAND                    16512 non-null  float64\n",
      " 8   NEAR BAY                  16512 non-null  float64\n",
      " 9   NEAR OCEAN                16512 non-null  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# At this point we are going to remove any features that we don't intend to train the model with\n",
    "dumpcolumns = [\"longitude\",\"latitude\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\"]\n",
    "print(dumpcolumns)\n",
    "X_train = X_train.drop(columns=dumpcolumns,axis=1)\n",
    "X_test = X_test.drop(columns=dumpcolumns,axis=1)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validating ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# simple function for initial judgement of these models\n",
    "def scoremodel(reg_model):\n",
    "    # testing the model with K-fold cross validation (using 10 folds)\n",
    "    scores = cross_val_score(reg_model, X_train, y_train, scoring=\"neg_mean_squared_error\",cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    print(\"Scores: \",rmse_scores)\n",
    "    print(\"Mean: \",rmse_scores.mean())\n",
    "    print(\"Standard Deviation: \",rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [69642.60584811 71379.12594638 71369.98715096 74555.94013165\n",
      " 72968.70315288 74831.00002703 68361.14512849 72746.22540469\n",
      " 75218.09095873 72202.00186093]\n",
      "Mean:  72327.48256098537\n",
      "Standard Deviation:  2120.0959388507335\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Starting simple with a Linear Regression\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "scoremodel(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [82110.43278754 82712.58740762 86490.43903517 84680.54997075\n",
      " 83549.21695164 86322.63260083 82044.94372132 80694.62721931\n",
      " 85151.01207758 88838.54193181]\n",
      "Mean:  84259.49837035524\n",
      "Standard Deviation:  2372.8003476435833\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Decision Tree Model\n",
    "\"\"\"\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "scoremodel(tree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [59036.82723391 57820.56650092 60702.32252645 63087.62833502\n",
      " 60970.86418776 63220.1745083  57520.05471056 57944.6887337\n",
      " 62916.70059696 60504.40248355]\n",
      "Mean:  60372.42298171179\n",
      "Standard Deviation:  2115.784664379974\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Random Forest Model\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "scoremodel(forest_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
